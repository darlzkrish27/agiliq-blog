<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>How performant is your Python web application</title>
        <link rel="stylesheet" href="/theme/css/main.css" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">agiliq_blog </a></h1>
                <nav><ul>
                    <li><a href="/category/html.html">html</a></li>
                    <li class="active"><a href="/category/markdown.html">markdown</a></li>
                    <li><a href="/category/rst.html">rst</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/how-performant-your-python-web-application.html" rel="bookmark"
           title="Permalink to How performant is your Python web application">How performant is your Python web application</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2017-11-15T08:56:01+05:30">
                Published: Wed 15 November 2017
        </abbr>
		<br />
        <abbr class="modified" title="2017-11-15T12:26:01+05:30">
                Updated: Wed 15 November 2017
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/akshar.html">akshar</a>
        </address>
<p>In <a href="/category/markdown.html">markdown</a>.</p>
<p>tags: <a href="/tag/gunicorn.html">gunicorn</a> </p>
</footer><!-- /.post-info -->      <p>This post tries to explain web application performance. <strong>Performance</strong> means the <strong>number of requests per second</strong> that can be served by a deployed application. </p>
<p>This post would help answer questions like:</p>
<ul>
<li>How <code>performant</code> is an application.</li>
<li>How much <code>load</code> can it handle.</li>
<li>How many <code>concurrent requests</code> can it serve.</li>
<li>How can you determine <code>requests per second</code> for an application.</li>
<li>What steps to take to increase <code>serving capability</code> for an application.</li>
</ul>
<p>This post has as much code as theory.</p>
<p>This post assumes that you have a basic understanding of processes, threads. You can read our <a href="http://agiliq.com/blog/2013/09/process-and-threads-for-beginners/" target="_blank">previous post</a> for basic understanding of processes and threads.</p>
<p>In any web application there are many urls and associated handlers/controllers for each url. A url might respond in 200ms while another url might take 3 seconds. While determining performance of an application, choose the url which will be used most often and determine its performance.</p>
<h3>Factors which determine performance</h3>
<p>There are many <code>factors</code> determining performance of an application. Major factors are:</p>
<ul>
<li>Application type</li>
<li>Application complexity</li>
<li>Web server</li>
<li>Physical server, i.e infrastructure</li>
<li>Web server configuration</li>
</ul>
<p>In this post we will see how changing <code>web server configuration</code> changes performance with other factors remaining constant.</p>
<p>Two major components of <code>web server configuration</code> are:</p>
<ol>
<li>Number of processes/workers</li>
<li>Number of threads</li>
</ol>
<p>We will also see what web server configuration should be preferred for which application type. Example: How increasing number of server processes boosts performance for some applications while it reduces performance for other application types.</p>
<h4>Application type</h4>
<p>Applications could be compute intensive or network intensive or I/O intensive. Compute intensive applications can't get any benefit by making number of server workers or threads greater than number of CPU cores.</p>
<p>Network intensive or I/O intensive applications can benefit a lot by making several server workers/threads run on each core.</p>
<h4>Application complexity</h4>
<p>Suppose a url handler makes two db calls and takes a second to respond. In such case reducing number of db calls to 1 will reduce response time by half and number of requests served per second will get doubled.</p>
<h4>Web server</h4>
<p>There are many web servers. eg: Apache, Gunicorn, uwsgi etc. Apache might be better than gunicorn and might be able to handle more requests per second than gunicorn.</p>
<h4>Physical server/Infrastructure</h4>
<p>Increasing the number of cores or memory will improve the performance. If a single core machine is able to handle 10 requests per second for a computationally intensive application, then a machine with 2 cores should be able to handle 20 requests per second.</p>
<p>This might need properly configuring the web server to get maximum utilization from physical server.</p>
<h4>Application server configuration</h4>
<p>Number of running web server processes influences performance. Similarly number of server threads in each process influences performance too.</p>
<h3>Demo server configuration</h3>
<p>Our demo physical server is a t1.micro instance with 1 GB RAM. It has a single core.</p>
<p>Demo application for this post uses Django/Python served from a Gunicorn application server.</p>
<p>Familiarity with Django would be helpful but you should be able to follow as long as you have understanding of any web framework.</p>
<h3>Demo application</h3>
<p>Our application has the following url:</p>
<div class="highlight"><pre><span></span>http://34.233.117.92:8000/static_content_sleep
</pre></div>


<p>The Django handler/controller for url <code>static_content_sleep</code> looks like:</p>
<div class="highlight"><pre><span></span>def static_content_sleep(request):
    st = time.time()  # Compute Start time
    print &quot;sleeping&quot;
    time.sleep(1)     # Simulate db call which takes 1 seconds
    print &quot;waking&quot;
    print time.time() - st, &quot;in this function&quot;  # Compute end time
    return HttpResponse(&quot;Woke up&quot;)
</pre></div>


<p>Most web applications would be working with a database to fetch data.</p>
<p>We don't have a database setup. We are assuming that db used by the handler responds in 1 second. We are simulating a db call by making the code execution sleep for 1 second.</p>
<p>This application is being served by Gunicorn web server. Gunicorn configuration looks like:</p>
<div class="highlight"><pre><span></span>workers = 1
threads = 1
bind = &#39;0.0.0.0:8000&#39;
daemon = False
</pre></div>


<p>The important configuration variables are <code>workers</code> and <code>threads</code>. Ignore others.</p>
<p>If you want to setup gunicorn on your physical server, you can refer our <a href="http://agiliq.com/blog/2013/08/minimal-nginx-and-gunicorn-configuration-for-djang/" target="_blank">previous post</a>.</p>
<p>We used default gunicorn configuration for <code>workers</code> and <code>threads</code>. The default configuration of gunicorn has following characteristics:</p>
<h4>workers</h4>
<p>Default is 1. This means that only one gunicorn process would be running on the physical server.</p>
<p>If we make it 2, it would mean that 2 gunicorn processes would be running on the server.</p>
<h4>threads</h4>
<p>Default is 1. This tells number of threads in each worker process. This means that each gunicorn worker is single threaded and isn't multithreaded.</p>
<h3>Making requests</h3>
<p>Let's make two simultaneous request to this url.</p>
<p>Making two requests from browser will not be simultaneous as switching from one browser tab to another tab might take you more than a second. In that case you cannot properly observe time taken by the server to process two simultaneous requests.</p>
<p>Let's write a Python function to make simultaneous requests and log the time.</p>
<div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">15</span><span class="p">]:</span> <span class="kn">from</span> <span class="nn">threading</span> <span class="kn">import</span> <span class="n">Thread</span>
<span class="n">In</span> <span class="p">[</span><span class="mi">16</span><span class="p">]:</span> <span class="kn">import</span> <span class="nn">requests</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">17</span><span class="p">]:</span> <span class="k">class</span> <span class="nc">UrlThread</span><span class="p">(</span><span class="n">Thread</span><span class="p">):</span>
    <span class="o">...</span><span class="p">:</span>     <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="o">...</span><span class="p">:</span>         <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;http://34.233.117.92:8000/static_content_sleep&#39;</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">18</span><span class="p">]:</span> <span class="k">def</span> <span class="nf">make_n_requests</span><span class="p">(</span><span class="n">num_requests</span><span class="p">):</span>
    <span class="o">...</span><span class="p">:</span>     <span class="n">threads</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="o">...</span><span class="p">:</span>     <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_requests</span><span class="p">):</span>
    <span class="o">...</span><span class="p">:</span>         <span class="n">threads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">UrlThread</span><span class="p">())</span>
    <span class="o">...</span><span class="p">:</span>     <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
             <span class="c1"># The requests will be almost simultaneous.</span>
             <span class="c1"># Second request will be made within nanoseconds of making the first request.</span>
    <span class="o">...</span><span class="p">:</span>     <span class="k">for</span> <span class="n">thread</span> <span class="ow">in</span> <span class="n">threads</span><span class="p">:</span>
    <span class="o">...</span><span class="p">:</span>         <span class="n">thread</span><span class="o">.</span><span class="n">start</span><span class="p">()</span> <span class="c1"># Threads will be started without waiting for response of previous threads</span>
    <span class="o">...</span><span class="p">:</span>     <span class="k">for</span> <span class="n">thread</span> <span class="ow">in</span> <span class="n">threads</span><span class="p">:</span>
    <span class="o">...</span><span class="p">:</span>         <span class="n">thread</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>  <span class="c1"># Wait for response for all the requests.</span>
    <span class="o">...</span><span class="p">:</span>     <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="o">...</span><span class="p">:</span>     <span class="k">print</span> <span class="s2">&quot;Time to get response for </span><span class="si">%d</span><span class="s2"> simultaneous requests&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_requests</span><span class="p">,),</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span>
</pre></div>


<p>You can use curl or a shell script or any programming language using which you can simulate <strong>n</strong> simultaneous requests.</p>
<p>Make 2 simultaneous requests</p>
<div class="highlight"><pre><span></span>In [19]: make_n_requests(2)
Time to get response for 2 simultaneous requests 2.622205019
</pre></div>


<p>Gunicorn log on server looks like:</p>
<div class="highlight"><pre><span></span>sleeping
waking
1.00131487846 in this function
sleeping
waking
1.00130581856 in this function
</pre></div>


<h4>Observation</h4>
<ul>
<li>Print statements of the handler are printed. Print statements are printed again.</li>
<li>Based on prints, we can infer that second request's execution started after completion of first request.</li>
</ul>
<p>Let's make 5 simultaneous requests and see what happens</p>
<div class="highlight"><pre><span></span>In [20]: make_n_requests(5)
Time to get response for 5 simultaneous requests 5.65813708305
</pre></div>


<p>Gunicorn log looks like:</p>
<div class="highlight"><pre><span></span>sleeping
waking
1.00114989281 in this function
sleeping
waking
1.0011370182 in this function
sleeping
waking
1.00114202499 in this function
sleeping
waking
1.00130295753 in this function
sleeping
waking
1.00131988525 in this function
</pre></div>


<p>You can see 5 sets of print statements.</p>
<h4>Observation</h4>
<ul>
<li>As we increase number of simultaneous requests, response time is proportionately increasing.</li>
<li>For 2 requests, server takes around 2 seconds to respond.</li>
<li>For 5 requests, server takes around 5 seconds to respond.</li>
<li>For 10 requests, it <code>would take</code> around 10 seconds to respond.</li>
</ul>
<p>Let's change gunicorn <code>threads</code>from its default value of 1 to 5.</p>
<div class="highlight"><pre><span></span>threads = 5
</pre></div>


<p>Gunicorn process will have 5 threads now. And each thread is capable of serving a request. Hence 5 requests can be simultaneosly served.</p>
<p>Restart gunicorn.</p>
<p>Let's make 5 simultaneous requests again.</p>
<div class="highlight"><pre><span></span>In [27]: make_n_requests(5)
Time to get response for 5 simultaneous requests 1.77244091034
</pre></div>


<p><strong> While earlier it was taking around 5 seconds to get 5 simultaneous requests processed, now it takes less than 2 seconds. </strong></p>
<p>Server log looks like:</p>
<div class="highlight"><pre><span></span>sleeping
 sleeping
sleeping
sleeping
sleeping
waking
1.001278162 in this function
 waking
1.00262784958 in this function
waking
1.00353288651 in this function
waking
1.00325298309 in this function
waking
1.0035841465 in this function
</pre></div>


<h4>Important Observation</h4>
<ul>
<li>Each gunicorn thread could handle a request.</li>
<li>Processor kept switching between all these 5 threads.</li>
<li>This way all 5 requests being processed by 5 different threads got a chance to execute concurrently without waiting for completion of any request.</li>
<li>Print pattern also suggests that execution of 5 requests started before waiting for completion of first request.</li>
</ul>
<p>We can accomplish this performance boost by increasing number of workers instead of number of threads. We will change threads back to 1 and increase <code>workers</code> to 5 instead.</p>
<div class="highlight"><pre><span></span>workers = 5
threads = 1
</pre></div>


<p>Make 5 simultaneous requests</p>
<div class="highlight"><pre><span></span>In [22]: make_n_requests(5)
Time to get response for 5 simultaneous requests 1.76864600182
</pre></div>


<p>Server gunicorn log looks like:</p>
<div class="highlight"><pre><span></span>sleeping
sleeping
sleeping
sleeping
sleeping
waking
1.00134015083 in this function
waking
1.00125384331 in this function
waking
1.00277590752 in this function
waking
1.00121593475 in this function
waking
1.00092220306 in this function
</pre></div>


<p>Here, processor executed 5 processes parallely.</p>
<p>Let's make 10 simultaneous requests:</p>
<div class="highlight"><pre><span></span>In [23]: make_n_requests(10)
Time to get response for 10 simultaneous requests 2.74328804016
</pre></div>


<p>Server log looks like:</p>
<div class="highlight"><pre><span></span>sleeping   -&gt; First 5 requests are assigned to 5 workers
sleeping
sleeping
sleeping
sleeping
waking     -&gt; One worker, say worker 1, finished execution.
waking     -&gt; Another worker, say worker 2, finished execution. This print was executed before last print statement of worker 1 could execute.
1.00396203995 in this function  -&gt; Worker 1 last print statement. Worker 1 free now and can serve another request.
1.00669813156 in this function  -&gt; Worker 2 last print statement. Worker 2 free now
sleeping   -&gt; Assigned to probably worker 1
waking     -&gt; Probably worker 3 woke up.
1.00510120392 in this function
sleeping
waking
1.00605106354 in this function
sleeping
sleeping
waking
1.00563693047 in this function
sleeping
waking
1.00345993042 in this function
waking
1.00495409966 in this function
waking
1.00393104553 in this function
waking
1.0027141571 in this function
waking
1.00151586533 in this function
</pre></div>


<h4>Observation</h4>
<ul>
<li>We made 10 simultaneous requests.</li>
<li>First 5 requests were assigned to 5 running gunicorn processes.</li>
<li>First 5 requests were concurrently handled during 1st second. 5 remaining requests were waiting to be executed during this time. During next second each gunicorn process picked up another request after completing a request. That's why it took around 2 seconds to get response for 10 requests.</li>
</ul>
<p>Let's use 2 threads with 5 workers</p>
<div class="highlight"><pre><span></span>threads = 2
workers = 5
</pre></div>


<p>Let's restart gunicorn. Now there are 5 gunicorn processes running and each process is running 2 threads.</p>
<div class="highlight"><pre><span></span>In [16]: make_n_requests(10)
Time to get response for 10 simultaneous requests 1.46275486946
</pre></div>


<p>Server log looks like:</p>
<div class="highlight"><pre><span></span>sleeping -&gt; &#39;sleeping&#39; repeated 10 times before any &#39;waking&#39;.
sleeping
sleeping
sleeping
sleeping
sleeping
sleeping
sleeping
sleeping
sleeping
waking
1.00119280815 in this function
waking
1.00499987602 in this function
waking
1.00233006477 in this function
waking
1.00144195557 in this function
waking
1.00114202499 in this function
waking
1.00117397308 in this function
waking
1.00114512444 in this function
waking
1.00120997429 in this function
waking
1.00124192238 in this function
waking
1.00117397308 in this function
</pre></div>


<h3>Inference</h3>
<p>Based on these examples we can infer that making number of threads/workers greater than number of cores improves the performance for a network intensive and I/O intensive application.</p>
<h4>Can we keep increasing workers and threads</h4>
<p>You have to keep RAM usage under consideration while tuning the number of workers and threads.</p>
<p>Code execution for a handler needs memory. While worker is processing a request, sufficient memory must be available. If handling each request needs 50 MB and you have 5 workers and 1 thread running, you must ensure that 250 MB free RAM is there after starting gunicorn.</p>
<h4>Performance with current configuration</h4>
<p>Curent configuration has 2 workers and 5 threads for each worker. So 10 requests will be handled concurrently.</p>
<p>Each request takes around 1 second to respond.</p>
<p>So with current configuration server can handle 10 requests per second.</p>
<p>If the handler is changed to <code>time.sleep(0.5)</code>, i.e if each request could respond in approximately 0.5 seconds then server would be able to handle 20 requests per second.</p>
<p>If we change number of workers to 3 and 5 threads for each worker, then with time.sleep(0.5), server would be able to handle 3*5*2, i,e 30 requests per second.</p>
<h4>Increase performance by increasing number of cores</h4>
<p>Suppose we use a machine with 2 cores.</p>
<p>On single core machine if we were using 2 workers, then on double core machine we should use 4 workers. This assumes that there is sufficient RAM available to be allocated to 4 workers.</p>
<p>A dual core machine would be able to handle 4*5, i.e 20 requests per second, assuming each request responds in a second.</p>
<p>If we found that 3 workers with 5 thread each is an optimum combination on a single core machine, then we should use 6 workers on a dual core machine.</p>
<h3>Computationally bound applications</h3>
<p>Earlier sections discussed about I/O bound applications. Let's talk about CPU bound applications.</p>
<p>App has a following url:</p>
<div class="highlight"><pre><span></span>http://34.233.117.92:8000/list_of_dict
</pre></div>


<p>The Django handler/controller for url <code>list_of_dict</code> looks like:</p>
<div class="highlight"><pre><span></span>def list_of_dict(request):
    print &quot;entered function&quot;
    st = time.time()
    for i in xrange(30000000):
            pass
    print time.time() - st, &quot;in this function&quot;
    return HttpResponse(json.dumps(&quot;a&quot;))
</pre></div>


<p>Let's change <code>UrlThread</code> used by <code>make_n_requests</code> to work with this new url.</p>
<div class="highlight"><pre><span></span>In [14]: class UrlThread(Thread):
    ...:     def run(self):
    ...:         resp = requests.get(&#39;http://34.233.117.92:8000/list_of_dict&#39;)
</pre></div>


<p>Let's change gunicorn configuration to have a single worker and single thread.</p>
<div class="highlight"><pre><span></span>workers = 1
threads = 1
</pre></div>


<p>Let's make 1 request to this url</p>
<div class="highlight"><pre><span></span>In [28]: make_n_requests(1)
Time to get response for 1 simultaneous requests 1.49780297279
</pre></div>


<p>Server log looks like:</p>
<div class="highlight"><pre><span></span>entered function
0.454895019531 in this function
</pre></div>


<p>It takes around 0.5 seconds in the handler as you can see from server log. And it takes around 1 second for request and response to travel on the wire. So in total it takes around 1.5 seconds.</p>
<p>Let's make 5 requests to this url</p>
<div class="highlight"><pre><span></span>In [32]: make_n_requests(5)
Time to get response for 5 simultaneous requests 2.94885587692
</pre></div>


<p>Server log looks like:</p>
<div class="highlight"><pre><span></span>entered function
0.460360050201 in this function
entered function
0.459032058716 in this function
entered function
0.462526082993 in this function
entered function
0.45965385437 in this function
entered function
0.460576057434 in this function
</pre></div>


<p>Each request takes around 0.5 seconds to complete. Plus there is an additional time for request and response to move over the wire. In total it takes around 3 seconds.</p>
<p>Time to get response for n requests is increasing linearly as we increase n.</p>
<p>With a single worker and single thread, time to get response for simultaneous requests was increasing linearly with number of requests in I/O bound handler too.</p>
<p>Let's change gunicorn <code>threads</code>from its default value of 1 to 5.</p>
<div class="highlight"><pre><span></span>threads = 5
</pre></div>


<p>Let's make 5 simultaneous requests again.</p>
<div class="highlight"><pre><span></span>In [33]: make_n_requests(5)
Time to get response for 5 simultaneous requests 3.37198781967
</pre></div>


<p>We didn't get any advantage by increasing number of threads. Instead the performance deteriorated.</p>
<p>Server log looks like:</p>
<div class="highlight"><pre><span></span>entered function
entered function
entered function
entered function
entered function
2.68351387978 in this function
 2.67835998535 in this function
2.67423701286 in this function
 2.67234015465 in this function
2.6794462204 in this function
</pre></div>


<p>Event different requests didn't complete in 0.5 second as was happening with single thread. The CPU time was split between 5 threads and so instead of 0.5 seconds it took 2.6 seconds for each request to complete.</p>
<h4>Observation</h4>
<ul>
<li>In CPU bound applications, CPU isn't idle. So multiple threads don't provide an advantage.</li>
<li>CPU time is split between threads, which infact leads to longer response time for each request.</li>
<li>Thread switching brings a performance hit. That's why we saw response time for 5 requests going up from 2.9 seconds to 3.3 seconds for 5 simultaneous requests.</li>
</ul>
<h3>Takeaways</h3>
<ul>
<li>There is no definite answer for how many workers and threads will provide maximum performance. It's a matter of tuning and finding out.</li>
<li>Making number of workers/threads greater than number of cores almost always leads to higher number of requests per second handling in a I/O bound application.</li>
<li>Making number of workers/threads greater than number of cores almost always leads to reduced number of requests per second handling in a CPU bound application.</li>
<li>Making number of workers/threads greater than number of cores leads to increase in response time for each request in a CPU bound application.</li>
</ul>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="http://getpelican.com/">Pelican</a></li>
                            <li><a href="http://python.org/">Python.org</a></li>
                            <li><a href="http://jinja.pocoo.org/">Jinja2</a></li>
                            <li><a href="#">You can modify those links in your config file</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="#">You can add links in your config file</a></li>
                            <li><a href="#">Another social link</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>